{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0187e6aa",
   "metadata": {},
   "source": [
    "### Building a Chatbot\n",
    "\n",
    "We'll go over an example of how to design and implement an LLM-Powered Chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "    * Conversational RAG: Enable a chatbot experience over an external source of data.\n",
    "    * Agents: Build a chatbot that can take actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f144cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "431b1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model='gemma2-9b-it', groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a8d28ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Aaron,\\n\\nThat's great! It's awesome that you're bringing your ASP.NET expertise into the world of AI.  \\n\\nAs a large language model, I can definitely help you on your journey. What specific areas of AI are you interested in learning about?\\n\\nFor example, are you looking to:\\n\\n* **Build AI-powered applications with ASP.NET?**\\n* **Understand machine learning concepts and algorithms?**\\n* **Explore deep learning and neural networks?**\\n* **Get hands-on with AI tools and libraries?**\\n\\nTell me more about your goals, and I can provide you with relevant resources, explanations, or even code examples to get you started.  \\n\\nLet's learn together!\\n\", response_metadata={'token_usage': {'completion_tokens': 156, 'prompt_tokens': 29, 'total_tokens': 185, 'completion_time': 0.283636364, 'prompt_time': 0.002540723, 'queue_time': 1.1638396869999998, 'total_time': 0.286177087}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-67d2a986-8ae9-4973-af5f-fbb833d51da4-0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Aaron and I'm senior developer in asp.net and learning AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3641fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Aaron, that you're a senior developer in ASP.NET, and that you're learning to be an AI engineer.  \\n\\nIs there anything else you'd like to tell me about your background or current projects? ğŸ˜Š  I'm here to learn more!  \\n\", response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 169, 'total_tokens': 235, 'completion_time': 0.12, 'prompt_time': 0.010169591, 'queue_time': 0.248288704, 'total_time': 0.130169591}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-19643eb7-4dfc-43cf-bb7d-f8f980cda844-0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Aaron and I'm senior developer in asp.net and learning AI engineer\"),\n",
    "        AIMessage(content=\"Hi Aaron,\\n\\nIt's great to meet you!\\n\\nThat's fantastic that you're transitioning from ASP.NET development into the world of AI engineering. Your background in software development will be incredibly valuable as you learn AI. \\n\\nWhat aspects of AI are you most interested in exploring? \\n\\nDo you have any specific projects or goals in mind?\\n\\nI'm here to help you along your journey.  I can provide information, answer questions, and even help you brainstorm ideas.  Let me know how I can be of assistance!\\n\"),\n",
    "        HumanMessage(content=\"Hey, What's my name, previous work and currently what am doing?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a9a7d",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use a Message Histroy class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da33f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # Created Dict\n",
    "\n",
    "def get_session_history(session_id: str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "787450a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d666ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Aaron and I'm senior developer in asp.net and learning AI engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70ed13ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Aaron,\\n\\nThat's great! It's awesome that you're making the leap into AI engineering. Your background in ASP.NET development will definitely be an asset as you learn. \\n\\nWhat specific areas of AI are you most interested in exploring? \\n\\nI can offer some resources and guidance based on your interests. For example, if you're interested in:\\n\\n* **Machine Learning:** We could discuss popular frameworks like TensorFlow or PyTorch, and how they can be used to build models for tasks like classification, regression, or natural language processing.\\n* **Deep Learning:** I could share information about neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs), which are powerful tools for image recognition, speech processing, and other complex tasks.\\n* **Computer Vision:** We could explore techniques for object detection, image segmentation, and image generation.\\n* **Natural Language Processing:** I can tell you about techniques for text classification, sentiment analysis, machine translation, and chatbot development.\\n\\nDon't hesitate to ask any questions you have. I'm here to help you on your AI journey!\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82d3fd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Aaron. ğŸ˜Š  You told me at the beginning of our conversation! \\n', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 278, 'total_tokens': 299, 'completion_time': 0.038181818, 'prompt_time': 0.015819496, 'queue_time': 0.24792114400000004, 'total_time': 0.054001314}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e5965a12-6e84-4a68-b671-564b1d00708c-0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47d2d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know!\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the config --> Session id\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke([HumanMessage(content=\"What's my name?\")], config=config1)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be90935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5add3fdb",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60ce28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af305698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Aaron, it's nice to meet you!\\n\\nWhat can I do for you today?  I'm happy to answer your questions and help in any way I can. ğŸ˜Š  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 30, 'total_tokens': 73, 'completion_time': 0.078181818, 'prompt_time': 0.002078122, 'queue_time': 0.249723565, 'total_time': 0.08025994}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd446b34-9f89-4041-bad1-31dd7269019c-0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Aaron\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a86406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecc9a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Aaron! It's nice to meet you.  \\n\\nWhat can I do for you today? ğŸ˜Š \\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is Aaron\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea4324",
   "metadata": {},
   "source": [
    "#### Multiple Input Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2bd8c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more complexity\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5548506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"à®µà®£à®•à¯à®•à®®à¯, à®à®°à®©à¯! \\n\\nà®¨à®¾à®©à¯ à®‰à®¤à®µà¯à®®à¯ à®’à®°à¯ à®‰à®¤à®µà®¿à®•à¯à®•à¯à®´à¯. \\n\\nà®à®©à¯à®©à®¾à®²à¯ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯ à®à®©à®•à¯à®•à¯ à®•à¯‡à®³à¯à®™à¯à®•à®³à¯. ğŸ˜Š \\n\\n(Hello, Aaron! \\n\\nI am a helpful assistant.\\n\\nAsk me anything you want. ğŸ˜Š) \\n\\n\\nLet me know what you'd like to know or do! \\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hi my name is Aaron\")], \"language\":\"tamil\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046ae30",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97ad12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "116a46dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à®µà®£à®•à¯à®•à®®à¯ Aaron!  ğŸ˜Š\\n\\nà®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®¤à®µà¯à®®à¯ à®’à®°à¯ à®ªà®¯à®©à¯à®ªà®¾à®© à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯. à®à®©à¯à®©à®¾à®²à¯ à®‰à®™à¯à®•à®³à¯ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯à®•à¯à®•à¯ à®šà®¿à®±à®¨à¯à®¤ à®®à¯à®±à¯ˆà®¯à®¿à®²à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®ªà®¤à®¿à®²à¯ à®…à®³à®¿à®•à¯à®• à®®à¯à®Ÿà®¿à®¯à¯à®®à¯. \\n\\nà®à®©à¯à®©à¯à®Ÿà¯ˆà®¯ à®‰à®¤à®µà®¿à®¯à¯ˆ à®à®ªà¯à®ªà®Ÿà®¿ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤à®²à®¾à®®à¯? ğŸ¤”  \\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "\n",
    "response = with_message_history.invoke({\"messages\": [HumanMessage(content=\"Hi, Im Aaron\")], \"language\":\"tamil\"}, config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff97d4",
   "metadata": {},
   "source": [
    "## Managing the Conversation History\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "'trim_message' - Helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef01feb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a good assistant\"),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    token_counter=model,\n",
    "    strategy=\"last\",\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    "    include_system=True\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi! I'm bob\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "184ddfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations or personal information about you, so I don't know what your favorite ice cream is.\\n\\nWhat's your favorite flavor?  ğŸ¦ğŸ˜Š\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) | prompt | model)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what ice cream do i like?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a86ec355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked \"What is 2 + 2?\".  \n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any other questions! ğŸ˜Š\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What math problem did i ask?\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e52d9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets wrap this in the Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\":{\"session_id\": \"chat6\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4da295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have access to past conversations, so I don't know your name. Would you like to tell me? ğŸ˜Š  \\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\" : \"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acca3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6406392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc2846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ca51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627edcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2103d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
